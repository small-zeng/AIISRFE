train{
    expname = gibson_im1_grids
    dataset_class = core.datasets.scene_dataset.SceneDatasetDNIMUnity
    model_class = core.model.network.MonoSDFNetwork
    loss_class = core.model.loss.MonoSDFIMLoss
    learning_rate = 5.0e-4
    lr_factor_for_grid = 20.0
    num_pixels = 1024
    checkpoint_freq = 10
    plot_freq = 10
    split_n_pixels = 4096
    BA = False
    BA_cam_lr = 0.004
    is_gt_pose = True
    BA_cam_size = 4
}
plot{
    plot_nimgs = 1
    resolution = 512
    grid_boundary = [-1.0, 1.0]
}
loss{
    # rgb_loss = torch.nn.L1Loss
    rgb_loss = torch.nn.MSELoss
    # rgb_loss = torch.nn.SmoothL1Loss
    # eikonal_weight = 0.1
    # smooth_weight = 0.005
    # depth_weight = 0.1
    # normal_l1_weight = 0.05
    # normal_cos_weight = 0.05
    eikonal_weight = 0.1
    smooth_weight = 0.005
    depth_weight = 0.1
    normal_l1_weight = 0.02
    normal_cos_weight = 0.02
    end_step = 200000
}
dataset{
    data_dir = Gibson
    img_res = [384, 384]
    scan_id = 1
    use_mask = False
    center_crop_type = center_crop_for_room 
}
model{
    feature_vector_size = 256
    scene_bounding_sphere = 1.0
    
    Grid_MLP = True

    implicit_network
    {
        d_in = 3
        d_out = 1
        dims = [256, 256]
        geometric_init = True
        bias = 0.6
        skip_in = [4]
        weight_norm = True
        multires = 6
        # sphere_scale= 10.0 # by zj
        inside_outside = True
        use_grid_feature = True
        divide_factor = 1.0 
    }

    rendering_network
    {
        mode = idr 
        d_in = 9 
        d_out = 4
        dims = [256, 256]
        weight_norm = True
        multires_view = 4
        per_image_code = False
    }
    density
    {
        params_init{
            beta = 0.1
        }
        beta_min = 0.0001
    }
    ray_sampler
    {
        near = 0.0
        N_samples = 64 
        N_samples_eval = 128 # by zj
        N_samples_extra = 32 
        eps = 0.1
        beta_iters = 10
        max_total_iters = 5
    }
}